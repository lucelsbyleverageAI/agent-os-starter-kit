{"createdAt":"2025-10-27T13:39:02.503Z","updatedAt":"2025-10-27T13:48:18.265Z","id":"QWwoe2PhpF6YKDMA","name":"N8N AI Agent Simple Template [READ ONLY - MAKE A COPY]","active":false,"isArchived":false,"nodes":[{"parameters":{"httpMethod":"POST","path":"77704423-b1a8-4f0a-abda-e99cfae32ca0","responseMode":"streaming","options":{}},"type":"n8n-nodes-base.webhook","typeVersion":2.1,"position":[1856,528],"id":"c6598722-86d9-4e97-8d46-640cbcf0cfa9","name":"Webhook","webhookId":"77704423-b1a8-4f0a-abda-e99cfae32ca0"},{"parameters":{"promptType":"define","text":"={{ $('Webhook').item.json.body.user_message }}","options":{"systemMessage":"=# Role\n\nYou are an AI assistant that uses tools to help the user achieve their task.\n\n# Task\n\nRespond to the user's request. Use your tools when needed to gather, create, or update information. Keep responses clear, concise, and focused on helping the user achieve their goal.\n\n# Tools available\n\n* **Memory tools:** Use these to remember or recall key facts, preferences, or context from previous interactions.\n* **File system tools:** Use these to read, write, or edit documents and data stored within scoped collections.\n* **Search tools:** Use these to find relevant information across available collections or documents.\n\n# Guidelines\n\n* Use tools when required to answer accurately or perform an action.\n* Summarise your actions so the user understands what you did.\n* Be concise by default, but expand when an explanation is helpful.\n* The user isn’t aware of which tools you used, so explain results in natural language.\n","enableStreaming":true}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":2.2,"position":[2208,528],"id":"a33d5857-bb25-41ff-aed9-fddc29aa9029","name":"AI Agent","retryOnFail":true},{"parameters":{"model":{"__rl":true,"value":"gpt-5","mode":"list","cachedResultName":"gpt-5"},"options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatOpenAi","typeVersion":1.2,"position":[1968,752],"id":"36135cfa-83ab-4b59-bf6b-8f706087f606","name":"OpenAI Chat Model","credentials":{"openAiApi":{"id":"tCOGOJ93xhYA7qpo","name":"OpenAi account"}}},{"parameters":{"respondWith":"allIncomingItems","options":{}},"type":"n8n-nodes-base.respondToWebhook","typeVersion":1.4,"position":[2560,528],"id":"38538282-921c-4d7f-ae30-b1a2b5c3c912","name":"Respond to Webhook"},{"parameters":{"content":"# LangGraph → n8n Agent Bridge\n\n#### What this is\nAn agent template showing how to wire an N8N agent into the frontend via our LangGraph backend.\n\nUse this as a template and extend as needed.\n\n#### How it works\nThe frontend sends messages to the LangGraph backend, which reformats and forwards them to your N8N webhook. N8N streams responses back, and LangGraph relays them to the client.\n\n#### Request flow\nUser (Frontend) → LangGraph Agent → N8N Webhook\n\n#### Payload structure\n```json\n{\n  \"thread_id\": \"191b1878-b3c4-498e-8c3f-338b8c14876a\",\n  \"user_message\": \"hi\",\n  \"config\": {\n    \"webhook_url\": \"http://...\",\n    \"user_id\": \"f243cd80-a497-4f8b-915b-097d0a868b00\",\n    \"thread_id\": \"191b1878-b3c4-498e-8c3f-338b8c14876a\",\n    \"assistant_id\": \"45cc340a-ae16-4835-a6a2-9589ce263763\",\n    \"run_id\": \"01999e4c-3397-73c2-83b7-50a66b5fe814\",\n    \"graph_id\": \"n8n_agent\"\n  }\n}\n```\n\n#### Key fields\n- `thread_id`: Conversation identifier (also present in `config`).\n- `user_message`: The user's input string.\n- `config`: LangGraph runtime context including:\n  - `user_id` (for user‑specific logic in workflows)\n  - `assistant_id` (agent configuration)\n  - `run_id`, `graph_id` (execution metadata)\n  - Any custom frontend configuration (JSON‑serialisable only)\n\n#### N8N webhook configuration\n- Method: POST\n- Content‑Type: application/json\n- Response mode: streaming (Respond to Webhook set to \"All Incoming Items\")\n- Behaviour: your workflow streams JSON objects; LangGraph forwards them to the client.\n\n---\n\n## Auth & Credentials Setup\n\nConfigure four credentials for this template agent:\n\n### 1. Chat model (LLM)\n- **Used by**: `AI Agent` / model node\n- **Configure**: Add your model provider credential (e.g. OpenAI) and select it on the model node\n\n### 2. Postgres (conversation memory)\n- **Used by**: `Postgres Memory` node\n- **Configure**: Create a Postgres credential and set the password to your `POSTGRES_PASSWORD`. Ensure host/DB/user match your compose config\n","height":1504,"width":1552},"type":"n8n-nodes-base.stickyNote","typeVersion":1,"position":[-288,-352],"id":"dc67d15a-b5df-4c97-8c3c-90d181a0f812","name":"Sticky Note"},{"parameters":{"sessionIdType":"customKey","sessionKey":"={{ $('Webhook').item.json.body.thread_id }}","tableName":"langconnect.n8n_chat_histories","contextWindowLength":25},"type":"@n8n/n8n-nodes-langchain.memoryPostgresChat","typeVersion":1.3,"position":[2656,944],"id":"b8c1964e-5385-408e-a3ef-b96bbb2130d5","name":"Postgres Chat Memory","credentials":{"postgres":{"id":"X78pH0HAnJIgfNp2","name":"Postgres account"}}},{"parameters":{"content":"# Model Node\n\n- **Configure credentials**\n  - Set your `OPENAI_API_KEY` (or replace with another provider’s key).\n- **Models**\n  - Select any available model for your account. You may swap the node for a different provider (Anthropic, OpenRouter, etc.) if preferred.\n- **Notes**\n  - Adjust rate limits and temperature to suit your use case.\n  - Be mindful of usage costs; long contexts and high output tokens increase spend.","height":336,"width":544,"color":6},"type":"n8n-nodes-base.stickyNote","typeVersion":1,"position":[1664,752],"id":"611347c6-ece9-42fe-b7a1-0bf67234786f","name":"Sticky Note1"},{"parameters":{"content":"## Webhook Node\nThis should work as it is pre-configured.\n- **Method**: POST\n- **Response Mode**: Set to \"streaming\" for real-time responses\n- **Response**: Your n8n workflow should stream JSON objects back to the LangGraph using a Respond to Webhook node set to 'All Incoming Items'","height":352,"width":336,"color":6},"type":"n8n-nodes-base.stickyNote","typeVersion":1,"position":[1664,320],"id":"4da5d99d-134a-437e-9c29-379995f139ab","name":"Sticky Note2"},{"parameters":{"content":"# Postgres Chat Memory Node\n\n- **Configure credentials**\n  - Set `POSTGRES_PASSWORD` in your environment (see `.env.local`).\n- **Connection (internal Docker network)**\n  - **Host**: `db`\n  - **Port**: `5432`\n  - **Database**: `postgres`\n  - **User**: `postgres`\n  - **Password**: `POSTGRES_PASSWORD`\n  - **SSL**: disabled for local development\n- **Purpose**\n  - Persists thread histories to `langconnect.n8n_chat_histories` for retrieval across workflow runs.\n- **Notes**\n  - Ensure the Supabase stack is running and reachable from the workflow container.\n  - If connection fails, verify the password and that the `db` service is healthy.","height":496,"width":544,"color":6},"type":"n8n-nodes-base.stickyNote","typeVersion":1,"position":[2272,784],"id":"9094878f-5a62-4a34-abb7-07eef191b717","name":"Sticky Note3"},{"parameters":{"model":{"__rl":true,"value":"claude-sonnet-4-20250514","mode":"list","cachedResultName":"Claude Sonnet 4"},"options":{"maxTokensToSample":10000,"thinking":false}},"type":"@n8n/n8n-nodes-langchain.lmChatAnthropic","typeVersion":1.3,"position":[2112,752],"id":"c1f98076-6ba6-4ba9-9203-aead74d88e86","name":"Anthropic Chat Model","credentials":{"anthropicApi":{"id":"QQ0ecnqQce2YIMuP","name":"Anthropic account"}}}],"connections":{"Webhook":{"main":[[{"node":"AI Agent","type":"main","index":0}]]},"AI Agent":{"main":[[{"node":"Respond to Webhook","type":"main","index":0}]]},"Postgres Chat Memory":{"ai_memory":[[{"node":"AI Agent","type":"ai_memory","index":0}]]},"Anthropic Chat Model":{"ai_languageModel":[[{"node":"AI Agent","type":"ai_languageModel","index":0}]]}},"settings":{"executionOrder":"v1"},"staticData":null,"meta":null,"pinData":{"Webhook":[{"json":{"headers":{"host":"localhost:5678","content-type":"application/json","accept":"*/*","accept-encoding":"gzip, deflate","user-agent":"Python/3.12 aiohttp/3.12.15","content-length":"886"},"params":{},"query":{},"body":{"thread_id":"191b1878-b3c4-498e-8c3f-338b8c14876a","user_message":"what files are in that collection? (use the collection id, not the name, as the input)","config":{"webhook_url":"http://localhost:5678/webhook/4dd6b459-552b-41da-8865-c8b60e4022ed","langgraph_auth_user_id":"f243cd80-a497-4f8b-915b-097d0a868b00","langgraph_auth_permissions":[],"langgraph_request_id":"b4fc90f2-7a34-4926-b783-2ecbdbe297de","__request_start_time_ms__":1759297418128,"__after_seconds__":0,"run_id":"01999e4c-3397-73c2-83b7-50a66b5fe814","thread_id":"191b1878-b3c4-498e-8c3f-338b8c14876a","graph_id":"n8n_agent","assistant_id":"45cc340a-ae16-4835-a6a2-9589ce263763","user_id":"7d3d91a4-46d0-4365-8ccf-4feecc02c2ac","__pregel_durability":"async","__pregel_task_id":"6a1c0720-e7f8-a08e-85b7-d020efc148bd","checkpoint_map":{"":"1f09e899-49d4-6a0a-8000-2cfb7d7e8937"},"checkpoint_id":null,"checkpoint_ns":"n8n_bridge:6a1c0720-e7f8-a08e-85b7-d020efc148bd"}},"webhookUrl":"http://localhost:5678/webhook/4dd6b459-552b-41da-8865-c8b60e4022ed","executionMode":"production"}}]},"versionId":"35a75153-e208-4767-beb8-8ce3baca2470","triggerCount":1,"tags":[]}