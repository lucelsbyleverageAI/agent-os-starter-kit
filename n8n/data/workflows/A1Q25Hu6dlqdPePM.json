{"createdAt":"2025-09-22T16:43:40.801Z","updatedAt":"2025-10-01T08:21:04.005Z","id":"A1Q25Hu6dlqdPePM","name":"N8N AI Agent Template [READ ONLY - MAKE A COPY]","active":true,"isArchived":false,"nodes":[{"parameters":{"httpMethod":"POST","path":"4dd6b459-552b-41da-8865-c8b60e4022ed","responseMode":"streaming","options":{}},"type":"n8n-nodes-base.webhook","typeVersion":2.1,"position":[0,-48],"id":"bb247a20-2d56-4752-bb47-337b461e7e6f","name":"Webhook","webhookId":"4dd6b459-552b-41da-8865-c8b60e4022ed"},{"parameters":{"promptType":"define","text":"={{ $json.body.user_message }}","options":{"systemMessage":"You are a helpful assistant with access to a variety of tools","enableStreaming":true}},"type":"@n8n/n8n-nodes-langchain.agent","typeVersion":2.2,"position":[400,-48],"id":"fe147e1c-ee1c-40e6-81eb-5192892ca2a8","name":"AI Agent","retryOnFail":true},{"parameters":{"model":{"__rl":true,"mode":"list","value":"gpt-4.1-mini"},"options":{}},"type":"@n8n/n8n-nodes-langchain.lmChatOpenAi","typeVersion":1.2,"position":[240,176],"id":"4a5b8f15-d6cc-4fa6-81c7-311ccc04f149","name":"OpenAI Chat Model","credentials":{"openAiApi":{"id":"tCOGOJ93xhYA7qpo","name":"OpenAi account"}}},{"parameters":{"respondWith":"allIncomingItems","options":{}},"type":"n8n-nodes-base.respondToWebhook","typeVersion":1.4,"position":[752,-48],"id":"4406d7f0-fe16-47f5-80b6-e5a0aef6fc3d","name":"Respond to Webhook"},{"parameters":{"content":"# LangGraph → n8n Agent Bridge\n\n#### What this is\nAn agent template showing how to wire an N8N agent into the frontend via our LangGraph backend, and connect it to the core components of our Agentic OS:\n- MCP server (custom tools)\n- Postgres (chat memories)\n- Memory tools (long‑term user memory)\n- Search tools (RAG over knowledge collections)\n\nN8N doesn’t match LangGraph’s auth model. In particular:\n- MCP is reachable only via a service account in N8N, so user‑scoped MCP tools aren’t available.\n- Collection search tools must be configured per collection.\n\nUse this as a template and extend either the N8N nodes or our backend endpoints as needed.\n\n#### How it works\nThe frontend sends messages to the LangGraph backend, which reformats and forwards them to your N8N webhook. N8N streams responses back, and LangGraph relays them to the client.\n\n#### Request flow\nUser (Frontend) → LangGraph Agent → N8N Webhook\n\n#### Payload structure\n```json\n{\n  \"thread_id\": \"191b1878-b3c4-498e-8c3f-338b8c14876a\",\n  \"user_message\": \"hi\",\n  \"config\": {\n    \"webhook_url\": \"http://...\",\n    \"user_id\": \"f243cd80-a497-4f8b-915b-097d0a868b00\",\n    \"thread_id\": \"191b1878-b3c4-498e-8c3f-338b8c14876a\",\n    \"assistant_id\": \"45cc340a-ae16-4835-a6a2-9589ce263763\",\n    \"run_id\": \"01999e4c-3397-73c2-83b7-50a66b5fe814\",\n    \"graph_id\": \"n8n_agent\"\n  }\n}\n```\n\n#### Key fields\n- `thread_id`: Conversation identifier (also present in `config`).\n- `user_message`: The user’s input string.\n- `config`: LangGraph runtime context including:\n  - `user_id` (for user‑specific logic in workflows)\n  - `assistant_id` (agent configuration)\n  - `run_id`, `graph_id` (execution metadata)\n  - Any custom frontend configuration (JSON‑serialisable only)\n\n#### N8N webhook configuration\n- Method: POST\n- Content‑Type: application/json\n- Response mode: streaming (Respond to Webhook set to “All Incoming Items”)\n- Behaviour: your workflow streams JSON objects; LangGraph forwards them to the client.\n\n### Auth & Credentials Setup\nConfigure four credentials for this template agent:\n- Chat model (LLM)\n  - Used by: `AI Agent` / model node.\n  - Configure: Add your model provider credential (e.g. OpenAI) and select it on the model node.\n- Postgres (conversation memory)\n  - Used by: `Postgres Memory` node.\n  - Configure: Create a Postgres credential and set the password to your `POSTGRES_PASSWORD`. Ensure host/DB/user match your compose config.\n- LangConnect service account (memory + search tools)\n  - Used by: all LangConnect Memory and RAG Search tool nodes.\n  - Credential type: Header Auth.\n  - Header name: `Authorization`\n  - Header value: `Bearer <LANGCONNECT_SERVICE_ACCOUNT_KEY>`\n  - Then select this credential in every Memory/Search node.\n- MCP service account (MCP client tools)\n  - Used by: `MCP Client` node.\n  - Credential type: Header Auth.\n  - Header name: `Authorization`\n  - Header value: `Bearer <MCP_SERVICE_ACCOUNT_KEY>`\n  - Then select this credential on the MCP Client node.\n\n#### Memory tools (summary)\n- Direct API usage to LangConnect memory endpoints (e.g. `http://langconnect:8080`).\n- Use service account auth; include `user_id` when impersonating:\n  - POST endpoints: `user_id` in JSON body (e.g. `/memory/add`, `/memory/search`)\n  - GET/PUT/DELETE: `user_id` as a query param (e.g. `/memory/{id}?user_id=...`)\n- Scope via `agent_id` and `run_id` as needed.\n\n#### Search tools (RAG) — important notes\n- Pre‑built endpoints:\n  - Semantic (vector): `POST /collections/{collection_id}/semantic_search`\n  - Keyword (full‑text): `POST /collections/{collection_id}/keyword_search`\n  - Hybrid (combined): `POST /collections/{collection_id}/hybrid_search`\n- LLM‑friendly options:\n  - `format_chunks_for_llm=true`: Return clean, hierarchical markdown.\n  - `return_surrounding_context=true`: Include surrounding context.\n    - Context means neighbouring chunks and/or full document excerpts around each hit, bounded by `max_context_characters` (default 2000).\n  - `limit`: Cap results (1–100).\n  - Hybrid only: `semantic_weight` balances vector vs keyword relevance.\n- CRITICAL: configure your collection\n  - You must set the `collection_id` in each Search Tool node’s URL path. This is easy to miss.\n  - Example: `http://langconnect:8080/collections/550e8400-e29b-41d4-a716-446655440000/semantic_search`\n  - We currently support one collection per tool. To expose multiple collections, duplicate the nodes with different hard‑coded `collection_id`s.\n- Improve tool clarity\n  - Update each node’s `toolDescription` to describe the specific collection (e.g. “Internal policy docs”) so the agent knows when/how to use it.\n\n#### Setup checklist\n- Choose search type(s): semantic, keyword, or hybrid; add the corresponding tool nodes.\n- Configure collection access: replace the `{collection_id}` placeholder in each node’s URL with your target collection UUID.\n- Describe the collection: adjust `toolDescription` with scope/context and usage hints.\n- Tune parameters (optional): `format_chunks_for_llm`, `return_surrounding_context`, `max_context_characters`, `limit`, and `semantic_weight` (hybrid).\n- Ensure langconnect auth is setup (see auth section above)\n- Extend if needed: add custom search endpoints or logic in `LangConnect` and point nodes to them.\n\n#### Notes\n- `config` only contains JSON‑serialisable values (complex runtime objects are stripped).\n- LangGraph manages bi‑directional streaming between N8N and the frontend.\n- Use `thread_id` to maintain dialogue continuity across requests.\n- `user_id` enables user‑specific behaviour in N8N flows.\n\nIf you want, I can also add a small “Troubleshooting” block (401/404/400 patterns) to this section.","height":2304,"width":1552},"type":"n8n-nodes-base.stickyNote","typeVersion":1,"position":[-2176,-1600],"id":"d76a4f0c-ffc6-4e62-9655-257f980813a9","name":"Sticky Note"},{"parameters":{"sessionIdType":"customKey","sessionKey":"={{ $json.body.thread_id }}","tableName":"langconnect.n8n_chat_histories","contextWindowLength":25},"type":"@n8n/n8n-nodes-langchain.memoryPostgresChat","typeVersion":1.3,"position":[400,1040],"id":"b255a014-6741-4860-9cf6-575d5d2e05fc","name":"Postgres Chat Memory","credentials":{"postgres":{"id":"X78pH0HAnJIgfNp2","name":"Postgres account"}}},{"parameters":{"content":"# Model Node\n\n- **Configure credentials**\n  - Set your `OPENAI_API_KEY` (or replace with another provider’s key).\n- **Models**\n  - Select any available model for your account. You may swap the node for a different provider (Anthropic, OpenRouter, etc.) if preferred.\n- **Notes**\n  - Adjust rate limits and temperature to suit your use case.\n  - Be mindful of usage costs; long contexts and high output tokens increase spend.","height":336,"width":544,"color":6},"type":"n8n-nodes-base.stickyNote","typeVersion":1,"position":[-160,160],"id":"a1d33651-4911-4754-b6b2-3284f8fb2c3e","name":"Sticky Note1"},{"parameters":{"content":"## Webhook Node\nThis should work as it is pre-configured.\n- **Method**: POST\n- **Response Mode**: Set to \"streaming\" for real-time responses\n- **Response**: Your n8n workflow should stream JSON objects back to the LangGraph using a Respond to Webhook node set to 'All Incoming Items'","height":352,"width":432,"color":6},"type":"n8n-nodes-base.stickyNote","typeVersion":1,"position":[-192,-256],"id":"073e5c40-2e76-4fd2-8442-73569ee5c4a8","name":"Sticky Note2"},{"parameters":{"content":"# Postgres Chat Memory Node\n\n- **Configure credentials**\n  - Set `POSTGRES_PASSWORD` in your environment (see `.env.local`).\n- **Connection (internal Docker network)**\n  - **Host**: `db`\n  - **Port**: `5432`\n  - **Database**: `postgres`\n  - **User**: `postgres`\n  - **Password**: `POSTGRES_PASSWORD`\n  - **SSL**: disabled for local development\n- **Purpose**\n  - Persists thread histories to `langconnect.n8n_chat_histories` for retrieval across workflow runs.\n- **Notes**\n  - Ensure the Supabase stack is running and reachable from the workflow container.\n  - If connection fails, verify the password and that the `db` service is healthy.","height":496,"width":544,"color":6},"type":"n8n-nodes-base.stickyNote","typeVersion":1,"position":[16,864],"id":"30556409-8ef5-4421-9615-ef258fb92b73","name":"Sticky Note3"},{"parameters":{"endpointUrl":"http://mcp-server:8001/mcp","serverTransport":"httpStreamable","authentication":"headerAuth","include":"selected","includeTools":["execute_code","tavily-map","tavily-crawl","tavily-extract","tavily-search"],"options":{"timeout":360000}},"type":"@n8n/n8n-nodes-langchain.mcpClientTool","typeVersion":1.1,"position":[1472,128],"id":"2ef8e128-4924-4fb2-a877-ce71b33b0c4c","name":"MCP Client","credentials":{"httpHeaderAuth":{"id":"RzStLdBK4VVr00xO","name":"MCP Header Auth"}}},{"parameters":{"content":"# MCP Client Node\n\n- **How to connect (inside Docker)**  \n  - Endpoint: `http://mcp-server:8001/mcp`  \n  - Auth: send exactly one header (configure with your mcp service account key)\n    ```\n    Authorization: Bearer <MCP_SERVICE_ACCOUNT_KEY>\n    ```\n  - From your host instead: `http://localhost:8002/mcp`\n\n- **What this client can do**  \n  - Use tools that are not user‑scoped (stateless/system tools defined under `custom` toolkits).  \n  - Health checks without auth:  \n    - `GET /health`  \n    - `GET /.well-known/oauth-protected-resource`\n\n- **What it cannot do (by design)**  \n  - No OAuth or extra headers: N8N’s MCP node cannot add user context (e.g. `user_id`, `thread_id`) or run an OAuth flow.  \n  - Calls authenticate as a single service account only; the server sets `user_id=\"service_account\"` and enforces restrictions.  \n  - Therefore, do not include tools that require user identity:\n    - **Memory tools**: blocked for service accounts (expect a 403).  \n    - **Arcade tools**: require per‑user OAuth; service account calls return an authorisation prompt URL you cannot complete from N8N.","height":672,"width":592,"color":6},"type":"n8n-nodes-base.stickyNote","typeVersion":1,"position":[1008,112],"id":"9a7c42dc-96d2-4198-b37b-7ca3e17faf92","name":"Sticky Note4"},{"parameters":{"toolDescription":"Add a new memory for the current user. Use this to store important facts, preferences, or context that should be remembered for future conversations. Provide the memory content and optional metadata.","method":"POST","url":"http://langconnect:8080/memory/add","authentication":"genericCredentialType","genericAuthType":"httpHeaderAuth","sendHeaders":true,"headerParameters":{"parameters":[{"name":"Content-Type","value":"application/json"}]},"sendBody":true,"bodyParameters":{"parameters":[{"name":"content","value":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('parameters0_Value', `The memory content to store`, 'string') }}"},{"name":"agent_id","value":"={{ $json.body.config.assistant_id }}"},{"name":"run_id","value":"={{ $json.body.config.run_id }}"},{"name":"user_id","value":"={{ $json.body.config.user_id }}"}]},"options":{}},"type":"n8n-nodes-base.httpRequestTool","typeVersion":4.2,"position":[-368,1088],"id":"56b45bdc-ea3d-4cb6-8e7e-67848e483719","name":"Add Memory","credentials":{"httpHeaderAuth":{"id":"F20PODB3nfvxF5Co","name":"Langconnect Header Auth"}}},{"parameters":{"content":"# Memory Tool Nodes\n\nOur memory tools provide direct integration with LangConnect’s Memory API, enabling agents to add, search, update, and delete memories without routing through the MCP server. Each node accepts execution context from earlier workflow steps (user_id, agent_id, run_id) and applies it to the API call.\n\n- **Direct API usage**: Calls `LangConnect` endpoints from n8n (internal network URL, e.g. `http://langconnect:8080`).\n- **Context-aware**: Pass `user_id` (required for service account usage), plus optional `agent_id` and `run_id`.\n- **Full coverage**: Add, search, get, update, delete, and history operations.\n\n#### Required configuration\n\n- **Service account key (mandatory)**:\n  - Ensure the environment variable `LANGCONNECT_SERVICE_ACCOUNT_KEY` is set for LangConnect.\n  - In n8n, create a “Header Auth” credential:\n    - Header name: `Authorization`\n    - Value: `Bearer <your LANGCONNECT_SERVICE_ACCOUNT_KEY>`\n  - Select this credential in each Memory Tool node.\n\n- **User impersonation with service account**:\n  - When using the service account key, include the target `user_id`:\n    - POST endpoints: in the JSON body (e.g. `/memory/add`, `/memory/search`).\n    - GET/PUT/DELETE endpoints: as a query parameter (e.g. `/memory/{id}?user_id=...`).\n\nThis setup ensures authenticated, user-scoped memory operations from n8n, with clear attribution and auditability.","height":688,"width":1168,"color":6},"type":"n8n-nodes-base.stickyNote","typeVersion":1,"position":[-1312,784],"id":"f9d94391-781b-4ecf-b27b-7a2c00cece93","name":"Sticky Note5"},{"parameters":{"toolDescription":"Search for memories based on a query. Returns memories semantically similar to the search query, ranked by relevance. Use this to recall relevant information from past conversations.","method":"POST","url":"http://langconnect:8080/memory/search","authentication":"genericCredentialType","genericAuthType":"httpHeaderAuth","sendHeaders":true,"headerParameters":{"parameters":[{"name":"Content-Type","value":"application/json"}]},"sendBody":true,"bodyParameters":{"parameters":[{"name":"query","value":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('parameters0_Value', `The search query to find relevant memories`, 'string') }}"},{"name":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('parameters1_Name', `Maximum number of results (default: 10, max: 100)`, 'string') }}","value":"=10"},{"name":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('parameters2_Name', `Minimum similarity threshold 0.0-1.0 (default 0.5)`, 'string') }}","value":"=0.5"},{"name":"user_id","value":"={{ $json.body.config.user_id }}"}]},"options":{}},"type":"n8n-nodes-base.httpRequestTool","typeVersion":4.2,"position":[-544,1280],"id":"b98eea0b-d773-4523-9714-b7501d1bddaa","name":"Search Memory","credentials":{"httpHeaderAuth":{"id":"F20PODB3nfvxF5Co","name":"Langconnect Header Auth"}}},{"parameters":{"toolDescription":"Get all memories for the current user. Returns a paginated list of all stored memories with their IDs, content, and timestamps. Use limit and offset for pagination.","url":"http://langconnect:8080/memory/all","authentication":"genericCredentialType","genericAuthType":"httpHeaderAuth","sendQuery":true,"parametersQuery":{"values":[{"name":"user_id","valueProvider":"fieldValue","value":"={{ $json.body.config.user_id }}"},{"name":"limit","valueProvider":"modelOptional"},{"name":"offset","valueProvider":"modelOptional"}]},"placeholderDefinitions":{"values":[{"name":"limit","description":"Maximum number of memories to return (default: 50, max: 1000)","type":"number"},{"name":"offset","description":"Number of memories to skip for pagination (default: 0)","type":"number"}]}},"type":"@n8n/n8n-nodes-langchain.toolHttpRequest","typeVersion":1.1,"position":[-256,1264],"id":"b854c6d9-d5a1-4b43-9a23-ed9a977522f0","name":"Get All Memories","credentials":{"httpHeaderAuth":{"id":"F20PODB3nfvxF5Co","name":"Langconnect Header Auth"}}},{"parameters":{"toolDescription":"Delete a specific memory by its ID. This permanently removes the memory from storage and cannot be undone.","method":"DELETE","url":"http://langconnect:8080/memory/{memory_id}","authentication":"genericCredentialType","genericAuthType":"httpHeaderAuth","sendQuery":true,"parametersQuery":{"values":[{"name":"user_id","valueProvider":"fieldValue","value":"={{ $json.body.config.user_id }}"}]},"placeholderDefinitions":{"values":[{"name":"memory_id","description":"The ID of the memory to delete","type":"string"}]}},"type":"@n8n/n8n-nodes-langchain.toolHttpRequest","typeVersion":1.1,"position":[-400,1264],"id":"9892047b-186e-4f2d-bbf8-566343d39c4d","name":"Delete Memory","credentials":{"httpHeaderAuth":{"id":"F20PODB3nfvxF5Co","name":"Langconnect Header Auth"}}},{"parameters":{"toolDescription":"Update an existing memory by its ID. Provide the memory_id and the new content.","method":"PUT","url":"http://langconnect:8080/memory/{memory_id}","authentication":"genericCredentialType","genericAuthType":"httpHeaderAuth","sendQuery":true,"parametersQuery":{"values":[{"name":"user_id","valueProvider":"fieldValue","value":"={{ $json.body.config.user_id }}"}]},"sendHeaders":true,"parametersHeaders":{"values":[{"name":"Content-Type","valueProvider":"fieldValue","value":"application/json"}]},"sendBody":true,"parametersBody":{"values":[{"name":"content","valueProvider":"modelOptional"},{"name":"metadata","valueProvider":"modelOptional"}]},"placeholderDefinitions":{"values":[{"name":"memory_id","description":"The ID of the memory to update","type":"string"},{"name":"content","description":"New content for the memory","type":"string"},{"name":"metadata","description":"New metadata for the memory as a JSON object","type":"json"}]}},"type":"@n8n/n8n-nodes-langchain.toolHttpRequest","typeVersion":1.1,"position":[-496,1088],"id":"535cb8e2-6b57-477e-8f1b-fcd353a14519","name":"Update Memory","credentials":{"httpHeaderAuth":{"id":"F20PODB3nfvxF5Co","name":"Langconnect Header Auth"}}},{"parameters":{"content":"# Search Tool Nodes\n\nOur search tools integrate directly with LangConnect’s Collections API to perform RAG over a chosen collection. We provide three pre‑configured endpoints:\n- **Semantic (Vector) search**: `POST /collections/{collection_id}/semantic_search`\n- **Keyword (Full‑Text) search**: `POST /collections/{collection_id}/keyword_search`\n- **Hybrid search**: `POST /collections/{collection_id}/hybrid_search`\n\n- **Direct API usage**: Calls LangConnect from n8n (internal URL, e.g. `http://langconnect:8080`).\n- **LLM‑friendly output**: Optional formatting for LLMs and surrounding context.\n- **Scope**: Each tool searches a single collection (specified via `collection_id` in the node URL).\n\n#### Key settings (tweak if needed)\n- **LLM formatting**: `format_chunks_for_llm=true` to return clean markdown.\n- **Context**: `return_surrounding_context=true`, `max_context_characters` to control context size (this setting returns more chunks before and after the matched chunks up to the context limit to provide more surrounding context from the relevant document).\n- **Relevance**:\n  - `limit` (1–100) to cap results.\n  - `semantic_weight` (hybrid only) balances vector vs keyword results.\n- **Filtering**: Optional `filter` JSON for metadata‑based narrowing.\n\n#### Important notes\n- This is a template implementation; you can adjust or extend the endpoints and behaviour in `LangConnect`.\n- We currently support one collection per tool. To expose multiple collections, **duplicate the nodes and hard‑code a different `collection_id` in each URL parameter**.\n- Please update each node’s `toolDescription` to describe the specific collection (e.g., “internal policy docs”), so the AI knows when/how to use it.\n\n#### Required configuration\n- **Service account key (mandatory)**:\n  - Ensure `LANGCONNECT_SERVICE_ACCOUNT_KEY` is set for LangConnect.\n  - In n8n, create a “Header Auth” credential:\n    - Header name: `Authorization`\n    - Value: `Bearer <your LANGCONNECT_SERVICE_ACCOUNT_KEY>`\n  - Select this credential in each Search Tool node.\n\n#### How to configure (template → usable)\n1. **Choose search type**: Add the nodes you need (keyword, semantic, or hybrid).\n2. **Set collection**: In each node’s URL, replace the `collection_id` placeholder with your target collection UUID.\n3. **Describe the collection**: Update `toolDescription` to explain what’s inside and when to use it.\n4. **Auth**: Select the “Header Auth” credential that uses your `LANGCONNECT_SERVICE_ACCOUNT_KEY`.\n5. **Tune parameters** (optional): Enable LLM formatting, set context size, adjust `limit`, and (for hybrid) `semantic_weight`.\n6. **Extend if needed**: Implement custom search endpoints or logic in `LangConnect` and point the nodes at your new routes.","height":1040,"width":1536,"color":6},"type":"n8n-nodes-base.stickyNote","typeVersion":1,"position":[896,992],"id":"9f290146-dce6-4032-b97f-dead3789b936","name":"Sticky Note6"},{"parameters":{"toolDescription":"Search a knowledge collection using semantic/vector similarity. Provide a natural language query to find relevant information. Returns the most semantically similar content from the collection.","method":"POST","url":"=http://langconnect:8080/collections/{YOUR_COLLECTION_ID}/semantic_search","authentication":"genericCredentialType","genericAuthType":"httpHeaderAuth","sendHeaders":true,"headerParameters":{"parameters":[{"name":"Content-Type","value":"application/json"}]},"sendBody":true,"bodyParameters":{"parameters":[{"name":"query","value":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('query', 'The natural language search query to find relevant information', 'string') }}"},{"name":"limit","value":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('limit', 'Maximum number of results to return (1-100, default: 10)', 'number') || 10 }}"},{"name":"format_chunks_for_llm","value":"true"},{"name":"return_surrounding_context","value":"true"},{"name":"max_context_characters","value":"2000"}]},"options":{}},"type":"n8n-nodes-base.httpRequestTool","typeVersion":4.2,"position":[2016,1168],"id":"0ad35c95-ed4d-4041-b597-7509e85fec31","name":"Semantic Search (Vector)","credentials":{"httpHeaderAuth":{"id":"F20PODB3nfvxF5Co","name":"Langconnect Header Auth"}},"notes":"Searches using semantic/vector similarity. Best for: conceptual queries, finding related ideas, natural language questions.\n\nConfiguration:\n- Set 'collection_id' in Workflow Settings → Static Data → collection_id\n- Or pass dynamically: Change URL to use {{ $json.collection_id }}\n- Requires LangConnect service account authentication"},{"parameters":{"toolDescription":"Search a knowledge collection using keyword matching. Provide specific keywords or phrases to find exact or similar matches. Returns content ranked by keyword relevance.","method":"POST","url":"=http://langconnect:8080/collections/{YOUR_COLLECTION_ID}/keyword_search","authentication":"genericCredentialType","genericAuthType":"httpHeaderAuth","sendHeaders":true,"headerParameters":{"parameters":[{"name":"Content-Type","value":"application/json"}]},"sendBody":true,"bodyParameters":{"parameters":[{"name":"keywords","value":"={{ $fromAI('keywords', 'Comma-separated keywords or phrases to search for (e.g., \"machine learning, neural networks, AI\")', 'string').split(',').map(k => k.trim()).filter(k => k) }}"},{"name":"limit","value":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('limit', 'Maximum number of results to return (1-100, default: 10)', 'number') || 10 }}"},{"name":"format_chunks_for_llm","value":"true"},{"name":"return_surrounding_context","value":"true"},{"name":"max_context_characters","value":"2000"}]},"options":{}},"type":"n8n-nodes-base.httpRequestTool","typeVersion":4.2,"position":[2192,1056],"id":"c3c541a1-d261-4032-82a0-f6a58129fd7c","name":"Keyword Search (Full-Text)","credentials":{"httpHeaderAuth":{"id":"F20PODB3nfvxF5Co","name":"Langconnect Header Auth"}},"notes":"Searches using keyword/full-text matching. Best for: specific terms, technical jargon, exact phrases, product names.\n\nConfiguration:\n- Set 'collection_id' in Workflow Settings → Static Data → collection_id\n- Or pass dynamically: Change URL to use {{ $json.collection_id }}\n- Requires LangConnect service account authentication"},{"parameters":{"toolDescription":"Search a knowledge collection using hybrid search (combines semantic and keyword search). Provide both a natural language query and specific keywords for best results. Returns content ranked by combined relevance.","method":"POST","url":"=http://langconnect:8080/collections/{YOUR_COLLECTION_ID}/hybrid_search","authentication":"genericCredentialType","genericAuthType":"httpHeaderAuth","sendHeaders":true,"headerParameters":{"parameters":[{"name":"Content-Type","value":"application/json"}]},"sendBody":true,"bodyParameters":{"parameters":[{"name":"query","value":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('query', 'The natural language search query', 'string') }}"},{"name":"keywords","value":"={{ $fromAI('keywords', 'Comma-separated keywords or phrases to search for (e.g., \"machine learning, neural networks, AI\")', 'string').split(',').map(k => k.trim()).filter(k => k) }}"},{"name":"limit","value":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('limit', 'Maximum number of results to return (1-100, default: 10)', 'number') || 10 }}"},{"name":"semantic_weight","value":"={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('semantic_weight', 'Weight for semantic vs keyword results (0.0-1.0, default: 0.5)', 'number') || 0.5 }}"},{"name":"format_chunks_for_llm","value":"true"},{"name":"return_surrounding_context","value":"true"},{"name":"max_context_characters","value":"2000"}]},"options":{}},"type":"n8n-nodes-base.httpRequestTool","typeVersion":4.2,"position":[2320,1184],"id":"eacff1c0-b64e-4a09-b6a9-84dc3e9d5710","name":"Hybrid Search (Vector + Keywords)","credentials":{"httpHeaderAuth":{"id":"F20PODB3nfvxF5Co","name":"Langconnect Header Auth"}},"notes":"Combines semantic and keyword search. Best for: comprehensive searches, when you want both conceptual and exact matches.\n\nConfiguration:\n- Set 'collection_id' in Workflow Settings → Static Data → collection_id\n- Or pass dynamically: Change URL to use {{ $json.collection_id }}\n- Adjust 'semantic_weight' (0.0=keywords only, 1.0=semantic only, 0.5=balanced)\n- Requires LangConnect service account authentication"}],"connections":{"Webhook":{"main":[[{"node":"AI Agent","type":"main","index":0}]]},"OpenAI Chat Model":{"ai_languageModel":[[{"node":"AI Agent","type":"ai_languageModel","index":0}]]},"AI Agent":{"main":[[{"node":"Respond to Webhook","type":"main","index":0}]]},"Postgres Chat Memory":{"ai_memory":[[{"node":"AI Agent","type":"ai_memory","index":0}]]},"MCP Client":{"ai_tool":[[{"node":"AI Agent","type":"ai_tool","index":0}]]},"Add Memory":{"ai_tool":[[{"node":"AI Agent","type":"ai_tool","index":0}]]},"Search Memory":{"ai_tool":[[{"node":"AI Agent","type":"ai_tool","index":0}]]},"Update Memory":{"ai_tool":[[{"node":"AI Agent","type":"ai_tool","index":0}]]},"Delete Memory":{"ai_tool":[[{"node":"AI Agent","type":"ai_tool","index":0}]]},"Get All Memories":{"ai_tool":[[{"node":"AI Agent","type":"ai_tool","index":0}]]},"Keyword Search (Full-Text)":{"ai_tool":[[{"node":"AI Agent","type":"ai_tool","index":0}]]},"Semantic Search (Vector)":{"ai_tool":[[{"node":"AI Agent","type":"ai_tool","index":0}]]},"Hybrid Search (Vector + Keywords)":{"ai_tool":[[{"node":"AI Agent","type":"ai_tool","index":0}]]}},"settings":{"executionOrder":"v1","callerPolicy":"workflowsFromSameOwner"},"staticData":null,"meta":{"templateCredsSetupCompleted":true},"pinData":{"Webhook":[{"json":{"headers":{"host":"localhost:5678","content-type":"application/json","accept":"*/*","accept-encoding":"gzip, deflate","user-agent":"Python/3.12 aiohttp/3.12.15","content-length":"886"},"params":{},"query":{},"body":{"thread_id":"191b1878-b3c4-498e-8c3f-338b8c14876a","user_message":"what tools do you have?","config":{"webhook_url":"http://localhost:5678/webhook/4dd6b459-552b-41da-8865-c8b60e4022ed","langgraph_auth_user_id":"f243cd80-a497-4f8b-915b-097d0a868b00","langgraph_auth_permissions":[],"langgraph_request_id":"b4fc90f2-7a34-4926-b783-2ecbdbe297de","__request_start_time_ms__":1759297418128,"__after_seconds__":0,"run_id":"01999e4c-3397-73c2-83b7-50a66b5fe814","thread_id":"191b1878-b3c4-498e-8c3f-338b8c14876a","graph_id":"n8n_agent","assistant_id":"45cc340a-ae16-4835-a6a2-9589ce263763","user_id":"f243cd80-a497-4f8b-915b-097d0a868b00","__pregel_durability":"async","__pregel_task_id":"6a1c0720-e7f8-a08e-85b7-d020efc148bd","checkpoint_map":{"":"1f09e899-49d4-6a0a-8000-2cfb7d7e8937"},"checkpoint_id":null,"checkpoint_ns":"n8n_bridge:6a1c0720-e7f8-a08e-85b7-d020efc148bd"}},"webhookUrl":"http://localhost:5678/webhook/4dd6b459-552b-41da-8865-c8b60e4022ed","executionMode":"production"}}]},"versionId":"7c9e8531-7b74-4df7-b315-2b3b63bacb48","triggerCount":1,"tags":[]}